# Model
model_name: "amuvarma/1b-delay-checkpoint-109139-of-109139"  # Replace with your base model must be compatible with the tokenizer and transformers library
tokenizer_name: "amuvarma/1b-delay-checkpoint-109139-of-109139"

# Training Args
epochs: 1
batch_size: 1
number_processes: 1
pad_token: 128263
save_steps: 5000
learning_rate: 5.0e-6

# Datasets
TTS_dataset: "amuvarma/brian-48k-KRVv68cDw2PBeOJypLrzaiI4kol2-enhanced-clipped-snacced-delay-TTS"

# Naming and paths
save_folder: "checkpoints"
project_name: "zac-zoe-1_5"
run_name: "5e6-0"

resize_dataset: false