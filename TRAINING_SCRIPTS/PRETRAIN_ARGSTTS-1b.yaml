# Model
model_name: "meta-llama/Llama-3.1-8B-Instruct" 
tokenizer_name: "meta-llama/Llama-3.1-8B-Instruct"

# Training Args
epochs: 1
batch_size: 1
number_processes: 8
pad_token: 128263
save_steps: 12000
learning_rate: 5.0e-5


# Datasets
TTS_dataset: "amuvarma/emilia-snac-merged-18m-TTS-3072"

# Naming and paths
save_folder: "checkpoints"
project_name: "135m-TTS"
run_name: "5e2-batch2-nofa"
